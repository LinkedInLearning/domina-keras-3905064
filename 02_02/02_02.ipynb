{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud5c4HOGiWXE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_palabras = 10000\n",
        "longitud_maxima = 100\n",
        "dim_embedding = 128\n",
        "\n",
        "(X_entrenamiento, y_entrenamiento), (X_prueba, y_prueba) = imdb.load_data(num_words=max_palabras)\n",
        "\n",
        "X_entrenamiento = pad_sequences(X_entrenamiento, maxlen=longitud_maxima)\n",
        "X_prueba = pad_sequences(X_prueba, maxlen=longitud_maxima)"
      ],
      "metadata": {
        "id": "Mp9x5XQuqh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", '', texto)\n",
        "    return texto\n",
        "\n",
        "def texto_a_secuencia(texto, word_index):\n",
        "    secuencia = []\n",
        "    for palabra in texto.split():\n",
        "        if palabra in word_index and word_index[palabra] < max_palabras:\n",
        "            secuencia.append(word_index[palabra] + 3)\n",
        "        else:\n",
        "            secuencia.append(2)\n",
        "    return secuencia"
      ],
      "metadata": {
        "id": "6hn7NYLKBlKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Sequential()\n",
        "modelo.add(Embedding(max_palabras, dim_embedding, input_length=longitud_maxima))\n",
        "modelo.add(LSTM(64, return_sequences=False, kernel_regularizer=l2(0.01)))\n",
        "modelo.add(Dropout(0.6))\n",
        "modelo.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "modelo.fit(X_entrenamiento, y_entrenamiento, epochs=10, batch_size=64,\n",
        "           validation_data=(X_prueba, y_prueba), callbacks=[early_stopping])\n",
        "\n",
        "puntuacion, precision = modelo.evaluate(X_prueba, y_prueba)\n",
        "print(f\"Precisión en el conjunto de prueba: {precision:.2f}\")\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "nuevos_comentarios = [\n",
        "    \"The movie was fantastic, really enjoyed the storyline and the performances!\",\n",
        "    \"This was the worst movie I have ever seen, completely terrible and boring.\",\n",
        "    \"An excellent movie with great acting and a compelling plot.\",\n",
        "]\n",
        "\n",
        "X_nuevos = []\n",
        "for comentario in nuevos_comentarios:\n",
        "    comentario_limpio = limpiar_texto(comentario)\n",
        "    secuencia = texto_a_secuencia(comentario_limpio, word_index)\n",
        "    X_nuevos.append(secuencia)\n",
        "\n",
        "X_nuevos = pad_sequences(X_nuevos, maxlen=longitud_maxima)\n",
        "\n",
        "predicciones = modelo.predict(X_nuevos)\n",
        "\n",
        "for i, comentario in enumerate(nuevos_comentarios):\n",
        "    sentimiento = 'Positivo' if predicciones[i][0] > 0.5 else 'Negativo'\n",
        "    print(f\"Comentario: {comentario}\")\n",
        "    print(f\"Predicción: {sentimiento} ({predicciones[i][0]:.2f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0xf1y1aqirM",
        "outputId": "f5dafb61-f931-4463-97ce-8ac2bba1d56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 192ms/step - accuracy: 0.6866 - loss: 1.0451 - val_accuracy: 0.8364 - val_loss: 0.3963\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 194ms/step - accuracy: 0.8816 - loss: 0.3107 - val_accuracy: 0.8454 - val_loss: 0.3628\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 182ms/step - accuracy: 0.9072 - loss: 0.2610 - val_accuracy: 0.8420 - val_loss: 0.3751\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 196ms/step - accuracy: 0.9271 - loss: 0.2164 - val_accuracy: 0.8323 - val_loss: 0.4289\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.8464 - loss: 0.3661\n",
            "Precisión en el conjunto de prueba: 0.85\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7873c646cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "Comentario: The movie was fantastic, really enjoyed the storyline and the performances!\n",
            "Predicción: Positivo (0.80)\n",
            "\n",
            "Comentario: This was the worst movie I have ever seen, completely terrible and boring.\n",
            "Predicción: Negativo (0.02)\n",
            "\n",
            "Comentario: An excellent movie with great acting and a compelling plot.\n",
            "Predicción: Positivo (0.81)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}